import binascii
import datetime
from typing import Optional

import boto3 as boto3

from amplio.utils import LambdaRouter, handler, QueryStringParam, Claim, BinBody, JsonBody
from ps import read_from_xlsx, read_from_s3, read_from_db, read_from_json, write_to_s3, publish_to_s3, export_to_db, \
    write_to_json, compare_program_specs

STATUS_OK = 'ok'
STATUS_FAILURE = 'failure'

OK_RESPONSE = 200
FAILURE_RESPONSE_400 = 400

PENDING_PROGSPEC_KEY = 'pending_progspec.xlsx'
PUBLISHED_PROGSPEC_KEY = 'pub_progspec.xlsx'
UNPUBLISHED_PROGSPEC_KEY = 'unpub_progspec.xlsx'
PROGSPEC_BUCKET = 'amplio-progspecs'

PUBLISHED_ARTIFACT_NAME = 'published'
UNPUBLISHED_ARTIFACT_NAME = 'unpublished'
PENDING_ARTIFACT_NAME = 'pending'
artifact_map = {
    PUBLISHED_ARTIFACT_NAME: PUBLISHED_PROGSPEC_KEY,
    UNPUBLISHED_ARTIFACT_NAME: UNPUBLISHED_PROGSPEC_KEY,
    PENDING_ARTIFACT_NAME: PENDING_PROGSPEC_KEY,
    'recipients': 'pub_recipients.csv',
    'content': 'pub_content.csv',
    'deployments': 'pub_deployments.csv'
}
BINARY_ARTIFACTS = [PUBLISHED_ARTIFACT_NAME, UNPUBLISHED_ARTIFACT_NAME, PENDING_ARTIFACT_NAME]

s3 = boto3.client('s3')
nl = '\n'


def _make_program_key(program: str, obj: str = ''):
    return '{}/{}'.format(program, obj)


def _make_s3_key(programid: str, artifact: str) -> Optional[str]:
    if artifact in artifact_map:
        return _make_program_key(programid, artifact_map[artifact])
    return None


def _get_s3_params_and_obj_info(key: str) -> (object, object):
    params = {'Bucket': PROGSPEC_BUCKET, 'Key': key}
    head = s3.head_object(**params)
    obj_info = {'Metadata': head.get('Metadata'),
                'VersionId': head.get('VersionId'),
                'Size': head.get('ContentLength'),
                'LastModified': head.get('LastModified').isoformat(),
                'Key': params.get('Key')}
    return params, obj_info


def _list_versions(bucket=PROGSPEC_BUCKET, prefix=''):
    """
    List objects an versions under Prefix in the given bucket.
    :param bucket: The bucket to be searched.
    :param prefix: Previx within the buckeet.
    :yields: Object versions.
    """
    paginator = s3.get_paginator("list_object_versions")
    kwargs = {'Bucket': bucket, 'Prefix': prefix}
    for versions in paginator.paginate(**kwargs):
        for version in versions.get('Versions', []):
            yield version


def _delete_versions(prefix: str, versions_to_keep=None):
    """
    Delete versions that match the given prefix. Optional string or iterable of versions to keep.
    :param prefix: The prefix under which to delete objects.
    :param versions_to_keep: A string or iterable of versions of objects to be kept.
    :return: None
    """
    if prefix is None or len(prefix) < 2:
        raise ValueError('Must specify a prefix to delete.')
    if versions_to_keep is None:
        versions_to_keep = []
    elif type(versions_to_keep) == str:
        versions_to_keep = [versions_to_keep]
    versions_to_keep = set(versions_to_keep)
    # We can delete up to 1000 objects at a time, so accumulate and delete keys in batches.
    to_delete = []
    for version in _list_versions(prefix=prefix):
        if not version.get('VersionId') in versions_to_keep:
            to_delete.append({'Key': prefix, 'VersionId': version.get('VersionId')})
        if len(to_delete) == 1000:
            s3.delete_objects(Delete={'Objects': to_delete}, Bucket=PROGSPEC_BUCKET)
            to_delete.clear()

    if len(to_delete) > 0:
        s3.delete_objects(Delete={'Objects': to_delete}, Bucket=PROGSPEC_BUCKET)


@handler
def publish(programid: QueryStringParam[str], email: Claim, comment: QueryStringParam[str] = 'No comment provided'):
    """
    Publish the program specification from the database. Creates pub_general.csv, pub_deployments.csv,
    pub_content.csv, and pub_recipients.csv objects in S3.
    :param programid: The program for which to publish the program specification.
    :param comment: A comment about the publish operation. May be automatically generated by publishing application.
    :param email: The email address of the user initiating the publish operation.
    :return: Any detected errors (These would be access errors; the data in the database is, by definition,
            good data).
    """
    print(f'Publish for program {programid} by {email}')
    comment = comment or 'No comment provided'
    metadata = {'submitter-email': email,
                'submitter-comment': comment,
                'submission-date': datetime.datetime.now().isoformat()}
    print(metadata)
    # Get the current program spec from the db
    db_spec = read_from_db(programid)
    ok, errors = publish_to_s3(db_spec, metadata=metadata)
    print(f'Publish result: {ok}, {errors}')
    if ok:
        result = {'status': STATUS_OK}
        response_code = OK_RESPONSE
    else:
        result = {'status': STATUS_FAILURE, 'errors': errors}
        response_code = FAILURE_RESPONSE_400
    return result, response_code


@handler
def download(programid: QueryStringParam[str], artifact: QueryStringParam[str], aslink: QueryStringParam[bool],
             email: Claim):
    """
    Returns a program spec artifact as the bytes of a file or a link to a file in S3.
    :param programid: The program for which the artifact is desired.
    :param artifact: Which artifact, one of 'unpublished', 'published', 'general', 'deployments', 'content',
                or 'recipients'. 'unpublished' is the unpublished program spec (what one sees in the Amplio
                Suite) as a .xlsx file, 'published' is the published .xlsx spreadsheet, the others are the
                corresponding .csv files.
    :param aslink: Boolean. If true, returns a link to the file.
    :param email: The user's email
    :return: {'status': status, 'data': bytes-or-link, 'object': metadata-about-object}
    """
    artifact = artifact.lower()
    key = _make_s3_key(programid, artifact)
    # If this is a request for the un-published program specification, we need to extract it from the database first.
    if artifact == UNPUBLISHED_ARTIFACT_NAME:
        metadata = {'submitter-email': email,
                    'submitter-comment': 'Unpublished created for download.',
                    'submission-date': datetime.datetime.now().isoformat()}
        # Get the current program spec from the db
        db_spec = read_from_db(programid)
        ok, errors = write_to_s3(db_spec, UNPUBLISHED_ARTIFACT_NAME, metadata=metadata)
    if key:
        params, obj_info = _get_s3_params_and_obj_info(key)
        obj_info['artifact'] = artifact
        if aslink:
            # set the save-as name.
            params['ResponseContentDisposition'] = f'filename="{programid}-{artifact_map[artifact]}"'
            obj_info['filename'] = f'{programid}-{artifact_map[artifact]}'
            signed_url = s3.generate_presigned_url('get_object', Params=params, ExpiresIn=600)
            result = {'status': STATUS_OK, 'url': signed_url, 'object': obj_info}
        else:
            obj = s3.get_object(**params)
            if artifact in BINARY_ARTIFACTS:
                bin_data = obj.get('Body').read()
                data = binascii.b2a_base64(bin_data).decode('ascii')
            else:
                data = obj.get('Body').read().decode('utf-8')

            result = {'status': STATUS_OK, 'data': str(data), 'object': obj_info}
        return result


@handler
def upload(data: BinBody, programid: QueryStringParam[str], email: Claim, return_diff: QueryStringParam[bool] = False,
           comment: QueryStringParam[str] = 'No comment provided'):
    """
    Uploads the binary contents of a .xlsx file to the pending program spec, s3://amplio-progspecs/{programid}/pending.
    """
    pending_spec, errors = read_from_xlsx(data)
    if pending_spec:
        print(f'Loaded new pending spec for {programid} from data')
        # Looks good, save to S3.
        metadata = {'submitter-email': email,
                    'submitter-comment': comment or 'No comment provided',
                    'submission-date': datetime.datetime.now().isoformat()}

        key = _make_program_key(programid, PENDING_PROGSPEC_KEY)
        put_result = s3.put_object(Body=data, Bucket=PROGSPEC_BUCKET, Metadata=metadata, Key=key)
        _delete_versions(key, versions_to_keep=put_result.get('VersionId'))
        result = {'status': STATUS_OK, 'versionid': put_result.get('VersionId')}
        if return_diff:
            print(f'Loaded published spec for {programid} to find diffs')
            # Load published spec for diff
            published_spec, errors = read_from_s3(programid)
            if published_spec:
                diff_result = compare_program_specs(published_spec, pending_spec)
                print(f'Diff from published spec for {programid}: {nl.join(diff_result)}')
                result['diff'] = diff_result
            else:
                # oops, couldn't load published spec
                print(f'Could not load published spec for {programid}: {nl.join(errors)}')
                result = {'status': STATUS_FAILURE, 'errors': errors}, FAILURE_RESPONSE_400
        return result
    else:
        print(f'Could not load new pending spec for {programid}: {nl.join(errors)}')
        return {'status': STATUS_FAILURE, 'errors': errors}, FAILURE_RESPONSE_400


@handler
def accept(programid: QueryStringParam[str], email: Claim, comment: QueryStringParam[str] = 'No comment provided',
           publish: QueryStringParam[bool] = False):
    result = {'status': STATUS_OK}
    errors = None
    print(
        f'Accept pending program spec for program {programid} by {email}. ' +
        f'Publish ?: {publish}.')
    pending_spec, errors = read_from_s3(programid, PENDING_PROGSPEC_KEY)
    if pending_spec:
        ok, errors = export_to_db(pending_spec)
        if ok:
            if publish:
                metadata = {'submitter-email': email,
                            'submitter-comment': comment,
                            'submission-date': datetime.datetime.now().isoformat()}
                ok, errors = publish_to_s3(pending_spec, metadata=metadata)
                if ok:
                    pending_key = _make_program_key(programid, PENDING_PROGSPEC_KEY)
                    _delete_versions(pending_key)
    if errors:
        print(f'Errors in accept for {programid}: {nl.join(errors)}')
        # return a 400 status code.
        result = ({'status': STATUS_FAILURE, 'errors': errors}, FAILURE_RESPONSE_400)
    return result


@handler(roles='')
def get_content(programid: QueryStringParam[str]):
    """
    Retrieves the current db program spec ss a JSON string.
    :param programid: The program whose spec is to be retrieved.
    :param email: The user requesting the data.
    :return: a JSON string with the current program spec.
    """
    db_spec, errors = read_from_db(programid)
    json_spec = write_to_json(db_spec, to_string=False)
    return json_spec


@handler(roles='AD,PM')
def put_content(programid: QueryStringParam[str], data: JsonBody, email: Claim,
                return_updated: QueryStringParam[bool] = True, return_diff: QueryStringParam[bool] = False):
    """
    Update one or more sections of the program spec.
    :param programid: The program whose spec is to be updated.
    :param data: The data.
    :param return_diff: If true, return a diff of the program spec.
    :return: the update status, and the diff if requested.
    """
    result = {'status': STATUS_OK}
    errors = None
    print(f'put content for {programid} by {email}, data: {data}')
    json_spec, errors = read_from_json(programid, data)
    if json_spec:
        if return_diff:
            db_spec, _ = read_from_db(programid)
            diff_result = compare_program_specs(db_spec, json_spec)
            print(f'Diff from db spec for {programid}: {nl.join(diff_result)}')
            result['diff'] = diff_result
        ok, errors = export_to_db(json_spec)
        if return_updated:
            result['updated'] = json_spec.write_to_json(to_string=False)
    if errors:
        print(f'Errors in put_content for {programid}: {nl.join(errors)}')
        # return a 400 status code.
        result = ({'status': STATUS_FAILURE, 'errors': errors}, FAILURE_RESPONSE_400)
    return result


def lambda_router(event, context):
    print(f'Event: {event}')
    the_router: LambdaRouter = LambdaRouter(event, context)
    action = the_router.path_param(0)
    print(
        f'Request {action} by user {the_router.claim("email") or "-unknown-"} for program {the_router.queryStringParam("programid") or "None"}')
    return the_router.dispatch(action)


if __name__ == '__main__':
    event = {'requestContext': {
        'authorizer': {'claims': {'email': 'bill@amplio.org'}}},
        'pathParameters': {'proxy': 'put_content'},
        'queryStringParameters': {'programid': 'TEST', 'return_diff': 'yes'},
        'body': '{"Nothing": [1,2,3]}'
    }
    lambda_router(event, {})
